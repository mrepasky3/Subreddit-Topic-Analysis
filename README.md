# Understanding Community Trends in Online Mental Health Forums (Subreddit-Topic-Analysis)

This code corresponds to the [CS 6471 Computational Social Science](https://www.cc.gatech.edu/classes/AY2022/cs6471_spring/) at Georgia Tech semester project. In this project, we conduct a Reddit-based case study on
college students which suffer from mental-health-related concerns and/or particpate in online discussion regarding mental health. To do so, we gather Reddit comment data
from December 2019 - December 2021 using the [Pushshift Reddit API](https://github.com/pushshift/api). We select comments from users posting in both mental health subreddits
(such as [r/Anxiety](https://www.reddit.com/r/Anxiety) and [r/Depression](https://www.reddit.com/r/Depression)) and in college-related subreddits (such as 
[r/college](https://www.reddit.com/r/college) and [r/gatech](https://www.reddit.com/r/gatech)). A series of topic models (LDA, NMF, and CombinedTM)
are fit to the data, followed by a time series partial correlation anaylsis and the construction of a set of vector autoregression models (one VAR model
per topic per topic model).

To avoid gathering the data (step 1 below), place the two folders [at this link](https://drive.google.com/drive/folders/11nL8VhAw70KdypHs00abc4vmTSJMGjpF?usp=sharing) in the top directory of this repository. To properly run the code, first generate a conda environment `conda create --name reddit_mental_health --file conda_requirements.txt`. Then, run the commands as outlined below.

The files have the following roles:  
1. Data Gathering: `extract_weekly_data_*_.py` files use the gathered list of subreddits and the pushshift API to pull comment data from Reddit and deposit them into files spanning one week each of data. These can be run directly from the command line using Python.
2. Topic Modeling: `{lda,nmf,ctm}_driver.py` files use utility functions in `utils.py` to clean, tokenize, and otherwise preprocess these data before fitting and visualizing LDA, NMF, and CombinedTM topic models.
    1. Generate topic models: `{lda,nmf,ctm}_driver.py --n_topics 15`
    2. Plot wordclouds: `python generate_wordclouds.py --topic_model {'lda','nmf','ctm'}`
4. Time Series Analysis: the `generate_time_series_*` methods in `utils.py` are used to generate time series arrays for each fitted model, and `time_series_analysis.py` visualizes these data, plots them as stack plots and line plots, performs partial correlation analysis, and fits VAR models. The plots can be generated by including the `--individual_plots`, `--gridplot`, and `--stackplot` flags.
    1. Generate daily time series: `python time_series_analysis.py --create_time series --topic_model {'lda','nmf','ctm'}`.
    2. Report PCF and signifance: `python time_series_analysis.py --partial_corr --topic_model {'lda','nmf','ctm'}`.
    3. Summarize largest significant PCF: `python time_series_analysis.py --top_corr_table --pcf_type 'individual' --topic_model {'lda','nmf','ctm'}`
    4. Fit and plot VAR models: `python time_series_analysis.py --VAR --pcf_type 'individual' --topic_model {'lda','nmf','ctm'}`

Much of the LDA/NMF topic modeling, pre-processing, and evaluation is adapted to our problem setting using the [Evaluate Topic Models: Latent Dirichlet Allocation (LDA)](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0) Towards Data Science article by Shashank Kapadia. The CTM is implemented using the [Contextualized Topic Models](https://github.com/MilaNLProc/contextualized-topic-models) Python module.
